<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title></title>
		<description>Things that occur to me</description>
		<link>/</link>
		<atom:link href="/feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>Presenting from a Docker Container</title>
				<description>&lt;p&gt;I’ve been presenting a bit recently on &lt;a href=&quot;http://www.docker.com&quot;&gt;docker&lt;/a&gt; and in an attempt to keep my presentation environment relatively simple, I decided to move off from using prezi which doesn’t have a linux client to something a bit more platform agnostic.&lt;/p&gt;

&lt;p&gt;After some looking around I settled on using &lt;a href=&quot;https://github.com/dploeger/jekyll-revealjs&quot;&gt;jekyll-revealjs&lt;/a&gt; which combines &lt;a href=&quot;https://jekyllrb.com/&quot;&gt;Jekyll&lt;/a&gt; publishing with the &lt;a href=&quot;http://lab.hakim.se/reveal-js/#/&quot;&gt;Reveal.JS&lt;/a&gt; HTML/JS presentation framework.&lt;/p&gt;

&lt;p&gt;This turns out to have quite a nice workflow for creating presentations as all your content is a series of markdown files and you can just commit changes to a git repository, which makes updating and modifying content for your presentation very easy, basically anywhere with a text editor does the job.&lt;/p&gt;

&lt;p&gt;Also once your presentation is complete you can access from any machine with a browser, which removes the ties of having to run on a specific operating system with specific presentation software installed.&lt;/p&gt;

&lt;p&gt;All that said, one slight downside which occurred to me is that whilst editing the presentation is as simple as running a text editor, when you’re presenting you need a working jekyll environment with a valid ruby install and the attendant gems. This sounded like a classic case where …. you guessed it…. Docker comes in handy !&lt;/p&gt;

&lt;p&gt;So I turned my presentation into a docker container :)&lt;/p&gt;

&lt;p&gt;The Dockerfile to do this was really pretty straightforward&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;FROM jekyll/jekyll
MAINTAINER Rory McCune &amp;lt;rorym@mccune.org.uk&amp;gt;
RUN mkdir /presentation
WORKDIR /presentation/
ADD . /presentation/
RUN chown -R 1000:1000 /presentation/*
CMD [&quot;jekyll&quot;, &quot;serve&quot;, &quot;-H&quot;, &quot;0.0.0.0&quot;]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;from the base jekyll install it basically just adds the git working directory to the image and runs jekyll to serve up the presentation.  The only gotcha I encountered was that the jekyll image very sensibly doesn’t run as root, so you need to chown your presentation files appropriately to avoid permission issues when you run the container.&lt;/p&gt;

&lt;p&gt;This is also a useful time to use a &lt;code class=&quot;highlighter-rouge&quot;&gt;.dockerignore&lt;/code&gt; file to avoid the container getting all the git history which it doesn’t need&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;.git
.gitignore
README.md
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;After that it’s just a questions of running the container and exposing the relevant port, and your presentation will run from any machine that has docker installed and a browser to view the content.&lt;/p&gt;

&lt;p&gt;In my case it’s let me have a backup of my talk sitting on a &lt;a href=&quot;http://presentation.pwndland.uk&quot;&gt;web server&lt;/a&gt; in case of last minute laptop problems.  I may also have created a Kubernetes cluster to run it, but that’s a story for another blog post :)&lt;/p&gt;
</description>
				<pubDate>Mon, 06 Jun 2016 10:01:39 +0100</pubDate>
				<link>/blog/2016/06/06/Presentation-In-A-Docker-Container/</link>
				<guid isPermaLink="true">/blog/2016/06/06/Presentation-In-A-Docker-Container/</guid>
			</item>
		
			<item>
				<title>Verizon DBIR Vulnerabilities Redux</title>
				<description>&lt;p&gt;Since my &lt;a href=&quot;https://raesene.github.io/blog/2016/04/30/Verizon-DBIR-Vulns-And-Cold-Fusion/&quot;&gt;last post&lt;/a&gt; on this there have been quite a few conversations had on twitter and we’ve now got &lt;a href=&quot;http://blog.kennasecurity.com/2016/05/collaborative-data-science-inside-the-2016-verizon-dbir-vulnerability-section/&quot;&gt;Kenna’s blog post&lt;/a&gt; with additional details on their methodology.&lt;/p&gt;

&lt;p&gt;I’m not going to try and cover the whole Top 10 but I think it’s worth looking at what Kenna have mentioned specifically with regards to the two FREAK vulnerabilities that I looked at last time. From Kenna’s blog post they define “Successful Exploitation” as&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Successful Exploitation is defined as one successful technical exploitation of a vulnerability on one machine at a particular timestamp. The event is defined as: 
1. An asset has a known CVE open. 
2. An attack come in that matches the signature for that CVE on that asset and 
3. One or more IOCs are detected/correlated post attack
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The “mystery sauce” here is part 3 around IOCs to detect a successful exploit, as that’s tricky to do with a MiTM attack like the two FREAK CVEs.  Attackers who successfully exploited that may just intercept sensitive data from the connection and them misuse it elsewhere, which is virtually impossible to correlate.&lt;/p&gt;

&lt;p&gt;Kenna also provided some interesting graphs for these vulns &lt;a href=&quot;http://www.stathat.com/s/4813HmgKhyPk&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;http://www.stathat.com/s/YSHQp2H6OAin&quot;&gt;here&lt;/a&gt; which show large spikes of activity initially followed by periodic smaller spikes through the year.&lt;/p&gt;

&lt;p&gt;Now, to me, that doesn’t really seem to fit a real attack on this issue as I kind of doubt that many people have the ability to crack 800k even weak RSA keys at once, also if someone had compromised that volume of SSL connections in a short space of time you’d have thought there would’ve been some fallout from it…&lt;/p&gt;

&lt;p&gt;However, what it does match is someone running a scanning tool over the large parts of the Internet looking for this vulnerability.  A scanning tool for this will negotiate a connection using the weak RSA keys, that’s how they work.&lt;/p&gt;

&lt;p&gt;Looking at the graph for CVE-2015-0204, we can see a …. huge spike in activity around March 2015, when… the researchers for the FREAK attack did a large scan looking for the issue. Looking at the &lt;a href=&quot;&quot;&gt;Freak Attack&lt;/a&gt; page we see a note&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;The following sites from the Alexa Top 10,000 websites permit RSA_EXPORT cipher suites, which potentially puts their users at risk from the FREAK attack. This list is current as of March 10 at 8:00 AM EST. 
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;indicating that they did a big scan in March 2015 which roughly correlates with the big spike in Kenna’s graph.  I’d also guess that a lot of other researchers would scan around that time as it was when the vulnerability was released.&lt;/p&gt;

&lt;p&gt;So whilst I can’t be really sure, if I was a betting man, I’d suggest that Kenna’s data doesn’t point to a sophisticated attacker exploiting an SSL MITM issue, but to a group of security researchers scanning a large number of sites after they had announced their vulnerability.&lt;/p&gt;

&lt;p&gt;The only mystery then is “what was the IOC seen on the affected hosts?”.&lt;/p&gt;

</description>
				<pubDate>Mon, 02 May 2016 10:01:39 +0100</pubDate>
				<link>/blog/2016/05/02/Verizon-DBIR-Vulns-Redux/</link>
				<guid isPermaLink="true">/blog/2016/05/02/Verizon-DBIR-Vulns-Redux/</guid>
			</item>
		
			<item>
				<title>Verizon DBIR, Vulnerabilities and Cold Fusion</title>
				<description>&lt;p&gt;So it’s Verizon DBIR time of year again and as with last year there seems to be a little bit of debate around the Top 10 exploited CVEs.  My twitter handle got copied in via some tweets from last year, so I thought I’d take the opportunity of providing a tester’s perspective on this. A more detailed and comprehensive look at this issue is available on the &lt;a href=&quot;https://blog.osvdb.org/2016/04/27/a-note-on-the-verizon-dbir-2016-vulnerabilities-claims/&quot;&gt;OSVDB Blog&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The thing that sprung out to me from the list was the first two mentioned as top 10 successfully exploited issues on the OSVDB blog.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;2015-03-05 – CVE-2015-1637 – Microsoft Windows Secure Channel (Schannel) RSA Temporary Key Handling EXPORT_RSA Ciphers Downgrade MitM (FREAK)&lt;/li&gt;
  &lt;li&gt;2015-01-06 – CVE-2015-0204 – OpenSSL RSA Temporary Key Handling EXPORT_RSA Ciphers Downgrade MitM (FREAK)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These CVEs related to the &lt;a href=&quot;https://freakattack.com/&quot;&gt;TLS FREAK attack&lt;/a&gt; which is an SSL cipher downgrade issue.  They jumped out at me as I see these on tests quite a bit and frankly, they don’t generally get rated as that serious of an issue.&lt;/p&gt;

&lt;p&gt;To draw an analogy if it turns out that these were two of the most successful attacks of 2015, this is kind of like (to me) a scientist saying they’ve perfected &lt;strong&gt;cold fusion&lt;/strong&gt;! a) it’s very unlikely and b) if true it’s extremely significant and deserves a lot more prominence than a footnote in the DBIR!&lt;/p&gt;

&lt;h2 id=&quot;why-is-it-unlikely&quot;&gt;Why is it unlikely?&lt;/h2&gt;

&lt;p&gt;It’s unlikely because to exploit this issues there’s a number of pre-requisites that need to be satisfied.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;MiTM&lt;/strong&gt; - This is the big one.  This issue is only exploitable when the attacker can sit in a position to intercept and modify traffic between the client and the server.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Client + Server Vuln. required&lt;/strong&gt; - Unlike some of the other SSL vulnerabilities we’ve seen this requires a vulnerable client and server. Most popular browsers got patched for this pretty quickly (either via auto-update or monthly patch) so the window of attack for most users was pretty small.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Cryptographic Power&lt;/strong&gt;.  We’re talking about the ability to mass crack ciphers here.  Now they’re not strong ones (that’s the point of the attack) but still this is some endevour to do at scale.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Detecting Exploitation&lt;/strong&gt;.  To detect exploitation requires that the sensor can tell when the ciphersuite is downgraded,  the attacker cracks the key and then presumably carries out some follow-on attack.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;what-does-it-mean&quot;&gt;What does it mean?.&lt;/h2&gt;

&lt;p&gt;So lets assume these are indeed two of the most exploited vulnerabilities of 2015, what would that mean?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;There are a set of attackers who have MiTM positions to attack large numbers of clients and servers on the Internet&lt;/li&gt;
  &lt;li&gt;Those attackers have the processing power to mass-crack cryptographic keys gathered from intercepted connections presumably quickly enough to do something with the key in question.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If this is true that’s a pretty serious problem, as this set of attackers are hardly going to stop what they’re doing once the patch rate for FREAK improves as it did quite rapidly.&lt;/p&gt;

&lt;p&gt;Anyway, from the OSVDB blog I understand that Kenna are planning a explanatory blog posting, which I very much look forward to reading.  Things I would really like to see in that would be&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Details of how detection successful exploitation of FREAK was achieved.&lt;/li&gt;
  &lt;li&gt;Details on what the attack group did with this afterwards.&lt;/li&gt;
  &lt;li&gt;Details of what threat group carried out these attacks.&lt;/li&gt;
&lt;/ul&gt;
</description>
				<pubDate>Sat, 30 Apr 2016 07:50:39 +0100</pubDate>
				<link>/blog/2016/04/30/Verizon-DBIR-Vulns-And-Cold-Fusion/</link>
				<guid isPermaLink="true">/blog/2016/04/30/Verizon-DBIR-Vulns-And-Cold-Fusion/</guid>
			</item>
		
			<item>
				<title>The Dangers of Docker.sock</title>
				<description>&lt;p&gt;One of the things about Docker is that whilst it provides you with a sane set of defaults from a security persective, it’s still pretty easy to quickly reduce the level of security/isolation provided if you deviate from those defaults without understanding the consequences.&lt;/p&gt;

&lt;p&gt;At the moment the Docker Engine authorization model is pretty basic (although there’s now a plugin API available, so hopefully this will improve soon). Essentially a process which can access the docker socket (usually at /var/run/docker.sock) or who can connect to the HTTPS API, can execute any command that the docker service can run, which generally provides access to the whole host system as the docker service runs as root.&lt;/p&gt;

&lt;p&gt;Where this can trip you up is where you might want to provide access to the Docker socket to a container to allow a process running in that container to extract information about other containers running on the service. This is typically done by mounting the Docker socket into the container with a switch like &lt;code class=&quot;highlighter-rouge&quot;&gt;-v /var/run/docker.sock:/var/run/docker.sock&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;There are a couple of projects that I’ve noticed so far which do this, one of the more popular is &lt;a href=&quot;https://github.com/jwilder/nginx-proxy&quot;&gt;nginx-proxy&lt;/a&gt; which uses access to the Docker socket to allow it to automatically create reverse proxy entries for other containers.&lt;/p&gt;

&lt;p&gt;The only real access control that’s possible with this kind of set-up is that you can set the access to be read only (e.g. &lt;code class=&quot;highlighter-rouge&quot;&gt;-v /var/run/docker.sock:/var/run/docker.sock:ro&lt;/code&gt;), however this could still be risky, depending on your configuration as commands like &lt;code class=&quot;highlighter-rouge&quot;&gt;docker inspect&lt;/code&gt; can leak secret information about running containers. (Also see the &lt;strong&gt;update&lt;/strong&gt; below)&lt;/p&gt;

&lt;p&gt;For example the official &lt;a href=&quot;https://hub.docker.com/_/postgres/&quot;&gt;Docker postgres image&lt;/a&gt; provides a startup command of &lt;code class=&quot;highlighter-rouge&quot;&gt;docker run --name some-postgres -e POSTGRES_PASSWORD=mysecretpassword -d postgres&lt;/code&gt; which uses an environment variable to set the postgres password.  So if another container gets access to the docker socket, they can extract that password from docker inspect and then likely make a connection straight to your database (unless you’ve disabled &lt;a href=&quot;https://docs.docker.com/engine/userguide/networking/default_network/container-communication/&quot;&gt;Inter-container commmunication&lt;/a&gt; ).&lt;/p&gt;

&lt;p&gt;So in general I’d recommend thinking very carefully before making use of a Docker image that requires access to the Docker socket, even with read-only permissions as it could open your environment up to some additional risks. Hopefully with future developments on the Docker authorization model it’ll get easier to allow a container introspection in a less risky manner…&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt; - After tweeting this article out @benhall &lt;a href=&quot;https://twitter.com/Ben_Hall/status/706879493135323136&quot;&gt;pointed out&lt;/a&gt; that actually the &lt;code class=&quot;highlighter-rouge&quot;&gt;ro&lt;/code&gt; setting on the volume mount doesn’t have a lot of effect in terms of security.  An attacker with ro access to the socket can still create another container and do something like mount /etc/ into it from the host, essentially giving them root access to the host.  So bottom line is don’t mount docker.sock into a container unless you trust its provenance and security…&lt;/p&gt;
</description>
				<pubDate>Sun, 06 Mar 2016 16:15:39 +0000</pubDate>
				<link>/blog/2016/03/06/The-Dangers-Of-Docker.sock/</link>
				<guid isPermaLink="true">/blog/2016/03/06/The-Dangers-Of-Docker.sock/</guid>
			</item>
		
			<item>
				<title>New Docker Compose Features</title>
				<description>&lt;p&gt;Along with the new version of Docker Engine which came out recently there were some handy updates to Docker Compose.  Back when I started looking at using compose and Docker containers for &lt;a href=&quot;https://raesene.github.io/blog/2015/08/15/set-up-a-complete-security-test-environment-with-command-and-docker-compose/&quot;&gt;pen testing&lt;/a&gt; one of the drawbacks was that there was no great way to define a shared area for all the containers to save their data to as part of the compose setup.&lt;/p&gt;

&lt;p&gt;So now with the new setup, we can use something like the example below, and then start it up with &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose run sectest /bin/bash&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This will start up four containers on the default private docker network, and provide a shell for the sectest container which we can use to run tools like nmap and metasploit.  Using this approach we get a couple of handy features.&lt;/p&gt;

&lt;p&gt;Because of docker links the names of the other containers are registered in each one, so for example in sectest we can &lt;code class=&quot;highlighter-rouge&quot;&gt;ping dradis&lt;/code&gt; and have that work ok.&lt;/p&gt;

&lt;p&gt;As the browser and the dradis/openvas instances are on the same private network we can access these browser based tools without having to expose them to the wider network.&lt;/p&gt;

&lt;p&gt;All the tools will have a directory in their filesystem at &lt;code class=&quot;highlighter-rouge&quot;&gt;/data&lt;/code&gt; which points to our data volume.  At the end of the test this can then be saved off either from within the tools or outside at host level.&lt;/p&gt;

&lt;p&gt;If you’re doing it at host level you need to note where the data’s actually stored.  To do that do&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;docker volume ls&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;to get the name of your data volume.  By default it’ll be the name of the directory you ran the docker-compose file from and then ‘-data’ after that.&lt;/p&gt;

&lt;p&gt;Once you know the name just do &lt;code class=&quot;highlighter-rouge&quot;&gt;docker inspect (name)&lt;/code&gt; and copy the files from there to whereever you’re storing them.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-yaml&quot; data-lang=&quot;yaml&quot;&gt;&lt;span class=&quot;s&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2&#39;&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;services&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;sectest&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; 
    &lt;span class=&quot;s&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;raesene/sectest&lt;/span&gt; 
    &lt;span class=&quot;s&quot;&gt;command&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/bin/bash&lt;/span&gt; 
    &lt;span class=&quot;s&quot;&gt;links&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; 
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;dradis&lt;/span&gt; 
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;openvas&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;firefox&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;data:/data&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;dradis&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; 
    &lt;span class=&quot;s&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;raesene/auto-docker-dradis&lt;/span&gt; 
    &lt;span class=&quot;s&quot;&gt;expose&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; 
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;3000&quot;&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;command&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;bundle exec rails server&lt;/span&gt; 
    &lt;span class=&quot;s&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;data:/data&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;openvas&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; 
    &lt;span class=&quot;s&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mikesplain/openvas&lt;/span&gt; 
    &lt;span class=&quot;s&quot;&gt;expose&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; 
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;443&quot;&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;9390&quot;&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;9391&quot;&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;data:/data&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;firefox&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;jess/firefox&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;links&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;dradis&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;openvas&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;environment&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;s&quot;&gt;DISPLAY&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;$DISPLAY&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/tmp/.X11-unix:/tmp/.X11-unix&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;data:/data&lt;/span&gt; 
&lt;span class=&quot;s&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;{}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

</description>
				<pubDate>Sun, 14 Feb 2016 16:15:39 +0000</pubDate>
				<link>/blog/2016/02/14/New-Docker-Compose-Features/</link>
				<guid isPermaLink="true">/blog/2016/02/14/New-Docker-Compose-Features/</guid>
			</item>
		
			<item>
				<title>Exploration in Docker Bridging</title>
				<description>&lt;p&gt;One of the things I’ve been interested to look at with docker is the network setup. By default when you bring up a docker container you get a network interface with a private IP address which can communicate with other containers on that network and can make outbound connections to the wider world, but isn’t visible to the wider network.&lt;/p&gt;

&lt;p&gt;Docker does this by attaching the container to a bridge on the host and setting up iptables NAT rules to allow traffic to flow from this bridged network to the wider external network.  There’s a couple of downsides to this approach.  Firstly you need to explicitly specify inbound ports at container launch time if you want to have server services receive connections.  When you do this, docker sets up port-forwarding to allow that traffic into the container.&lt;/p&gt;

&lt;p&gt;The problem with this approach is that if you’re running a service that sets ports up on the fly or which may change port during it’s runtime (e.g. metasploit) this is a bit on the inflexible side.&lt;/p&gt;

&lt;p&gt;The other downside is the use of NAT, which can cause issues with some networking tools that make a large number of network connections (e.g. nmap).&lt;/p&gt;

&lt;p&gt;One option to address this is to use the docker option &lt;code class=&quot;highlighter-rouge&quot;&gt;-net=host&lt;/code&gt; which essentially has the container run with the hosts network settings.  However one slight problem there is…. it doesn’t work with user namespaces, which I’m keen on having enabled.&lt;/p&gt;

&lt;p&gt;So ideally I’d like another option which provides no-NAT access to a container, ideally with an IP address on the host network subnet, with user namespaces enabled.  This is kind of similar to the VMWare Workstation/fusion setup with bridged networking.&lt;/p&gt;

&lt;p&gt;I had quite a dig around in the official docker documentation to see if this kind of setup is possible using in-built functionality and I didn’t see a way of doing this, so a little manual work is required. However I did find some interesting references to working out this kind of problem notably this &lt;a href=&quot;https://stackoverflow.com/questions/25529386/how-can-i-set-a-static-ip-address-in-a-docker-container&quot;&gt;StackOverflow post&lt;/a&gt; and &lt;a href=&quot;http://blog.oddbit.com/2014/08/11/four-ways-to-connect-a-docker/&quot;&gt;this&lt;/a&gt; slightly older post on Docker networking.&lt;/p&gt;

&lt;p&gt;First in one shell we need to start our target container.  We use the option &lt;code class=&quot;highlighter-rouge&quot;&gt;--net=none&lt;/code&gt; to setup the container without having docker do it’s usual network setup routines.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot; data-lang=&quot;shell&quot;&gt;docker run -it --net&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;none --name&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;nettest ubuntu:14.04 /bin/bash&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Next we need to create our virtual interface as below, I’ve called it &lt;code class=&quot;highlighter-rouge&quot;&gt;virtual0&lt;/code&gt; , in my case &lt;code class=&quot;highlighter-rouge&quot;&gt;eno16777736&lt;/code&gt; is the name of my host ethernet interface&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot; data-lang=&quot;shell&quot;&gt;sudo ip link add virtual0 link eno16777736 &lt;span class=&quot;nb&quot;&gt;type &lt;/span&gt;macvlan mode bridge&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;After we’re done that we need to add the virtual0 interface to the container, so we need to know the pid, which we can get from docker inspect.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot; data-lang=&quot;shell&quot;&gt;docker inspect --format &lt;span class=&quot;s1&quot;&gt;&#39;{ { .State.Pid }}&#39;&lt;/span&gt; nettest&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Then we create a link in /var/run/netns and set the netns of the virtual0 interface to be the same as our container.  In the examples below 3463 is the pid returned by the docker inspect command above.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot; data-lang=&quot;shell&quot;&gt;sudo mkdir -p /var/run/netns
sudo ln -s /proc/3463/ns/net /var/run/netns/3463
sudo ip link &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;virtual0 netns 3463&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We can then bring up the interface and apply an IP address.  Doing this inside the container doesn’t work from a permissions standpoint so it can be done with the &lt;code class=&quot;highlighter-rouge&quot;&gt;ip netns exec&lt;/code&gt; command from the host&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot; data-lang=&quot;shell&quot;&gt;sudo ip netns &lt;span class=&quot;nb&quot;&gt;exec &lt;/span&gt;3463 ip link &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;virtual0 up&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;and we can then assign a DHCP address from the host network DHCP server to the container&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot; data-lang=&quot;shell&quot;&gt;sudo ip netns &lt;span class=&quot;nb&quot;&gt;exec &lt;/span&gt;3463 dhclient virtual0&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Obviously doing all this manually is likely to be a bit much trouble for most use-cases, but I think with a bit of automation it could come in handy for some tasks which need a bit more flexibility in networking than the default docker configuration.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Edit:&lt;/strong&gt; I did find &lt;a href=&quot;https://github.com/gopher-net/macvlan-docker-plugin&quot;&gt;this project&lt;/a&gt; which looks to address the same problem, but at the moment it doesn’t seem to work for me…&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Edit2:&lt;/strong&gt; Well that was quick. The problems I had with the macvlan docker plugin got fixed (thanks to @nerdalert), so for a faster/less manual solution to this problem I’d recommend having a look at the link in the first edit!&lt;/p&gt;
</description>
				<pubDate>Sun, 07 Feb 2016 14:45:39 +0000</pubDate>
				<link>/blog/2016/02/07/Exploration-in-Docker-bridging/</link>
				<guid isPermaLink="true">/blog/2016/02/07/Exploration-in-Docker-bridging/</guid>
			</item>
		
			<item>
				<title>Docker 1.10 Notes - User Namespaces</title>
				<description>&lt;p&gt;So Docker 1.10 has just landed and with it a number of great new security enhancements.  One of the main ones is the enabling of User Namespaces.  This adds an extra level of protection as processes running in a container as root will not be running as root on the host Operating System, which makes it harder for a rogue process to break out of the container.&lt;/p&gt;

&lt;p&gt;When I downloaded 1.10 as an upgrade to an existing 1.9.1 install on Ubuntu, I noticed that User Namespaces don’t seem to be enabled by default, so I thought it would be worth noting how I enabled it as it’s a handy feature to be running.&lt;/p&gt;

&lt;p&gt;To get this working on Ubuntu 15.10, which uses systemd, I did this&lt;/p&gt;

&lt;p&gt;copy the base systemd config file to /etc/systemd/system&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo cp /lib/systemd/system/docker.service /etc/systemd/system/&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;It’s not likely to be a good idea to modify the one in /lib/systemd/system/ as it could be overwritten by later package downloads.&lt;/p&gt;

&lt;p&gt;Once you’ve done that you need to tell docker to remap the userns.  This can be done to an explicitly chosen uid:gid, but the basic default option will probably work fine for a lot of use-cases.&lt;/p&gt;

&lt;p&gt;So in /etc/systemd/system/docker you can edit&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ExecStart=/usr/bin/docker daemon -H fd://&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;to&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ExecStart=/usr/bin/docker daemon --userns-remap=default -H fd://&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;and then restart docker with&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo systemctl daemon-reload&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo systemctl restart docker&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Once you’ve done that you can check to make sure that it’s working by running a process in a container as root and look at what UID is being shown on the host.&lt;/p&gt;

&lt;p&gt;So something like&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;docker run -it ubuntu:14.04 top&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;should run the top process as root in the container and you can then do ps -ef or similar on the host OS and check what UID is in use.  In my example if came out looking like&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;165536     2347   2323  0 21:20 pts/0    00:00:00 top&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;So, no longer running as root , yay!&lt;/p&gt;

&lt;p&gt;One quick thing I noticed is that a side-effect of enabling userns-remap was that all my downloaded images were no longer visible, so I had to re-download the one’s I had.  So it’s defintely worth trying this change out on test systems before rolling out to production!&lt;/p&gt;

&lt;p&gt;You can back up your existing images with something like&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;docker save&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;if needed and it’s also worth noting that if you disable userns again, your original images will be available.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;EDIT&lt;/strong&gt; I got a mail from &lt;a href=&quot;https://twitter.com/estesp&quot;&gt;Phil Estes&lt;/a&gt; who has some good additional info. about the reasons that images aren’t visible when you enable userns, which I thought would be good to add here in case anyone finds this blog about it before the other ones that Phil mentions below.&lt;/p&gt;

&lt;p&gt;–&lt;/p&gt;

&lt;p&gt;“This segregation of image &amp;amp; layer content separated by user/group mapping is required because of file ownership within these image layers. 
If we tried to use the same layers in a remapped range environment it would nearly operate as a read-only environment, or worse, given the UIDs/GIDs used within your user namespaced process would have no write access to most directories and probably also not have read access to many as well due to permission bits in the original content.&lt;/p&gt;

&lt;p&gt;So, instead of trying to do all kinds of funny “chown” tricks on use of the content (which would then need to be “chowned” back later in case you then run your daemon with different mappings or with user namespaces off), we basically create a new “root” cache that is empty when you start with a specific uid/gid mapping.  As you pull content it acts the same as any daemon and will be there for use when that mapping is enabled.  If you restart your daemon with user namespaces disabled, then all the prior content is there as you noted.&lt;/p&gt;

&lt;p&gt;These details are also explained in &lt;a href=&quot;https://integratedcode.us/2015/10/13/user-namespaces-have-arrived-in-docker/&quot;&gt;my blog post&lt;/a&gt; on the topic as well as the &lt;a href=&quot;https://docs.docker.com/engine/reference/commandline/daemon/#daemon-user-namespace-options&quot;&gt;official documentation on user namespaces&lt;/a&gt;. “&lt;/p&gt;
</description>
				<pubDate>Thu, 04 Feb 2016 20:30:39 +0000</pubDate>
				<link>/blog/2016/02/04/Docker-User-Namespaces/</link>
				<guid isPermaLink="true">/blog/2016/02/04/Docker-User-Namespaces/</guid>
			</item>
		
			<item>
				<title>Is This Thing on </title>
				<description>&lt;p&gt;One of the perenial problems of being an infrequent blogger is of course, you forget exactly how you used to do things…&lt;/p&gt;

&lt;p&gt;So this post is just to make sure I’ve actually remembered how this is all set-up before I write something more substantive :)&lt;/p&gt;
</description>
				<pubDate>Sun, 31 Jan 2016 19:36:39 +0000</pubDate>
				<link>/blog/2016/01/31/is-this-thing-on/</link>
				<guid isPermaLink="true">/blog/2016/01/31/is-this-thing-on/</guid>
			</item>
		
			<item>
				<title>Set-up a Complete Security Test Environment with One Command and Docker Compose</title>
				<description>&lt;p&gt;Following on from my last post on &lt;a href=&quot;http://raesene.github.io/blog/2015/07/23/using-docker-for-security-testing/&quot;&gt;Using Docker for Security Testing&lt;/a&gt;, I thought it would be interesting to see if we can set-up an even more automated environment by using &lt;a href=&quot;https://www.docker.com/docker-compose&quot;&gt;Docker Compose&lt;/a&gt;.  Docker Compose is a means of creating a linked set of containers, which you can configure to be started up together, so useful where you want to make use of multiple systems at the same time.&lt;/p&gt;

&lt;p&gt;For the use case of Security Testing I was thinking it would be nice to have containers which provide a service that you connect to over a network port, for example &lt;a href=&quot;http://dradisframework.org/&quot;&gt;Dradis&lt;/a&gt; or &lt;a href=&quot;http://www.openvas.org/&quot;&gt;OpenVAS&lt;/a&gt;, alongside your main command line driven container which has tools that you’re more likely to use interactively on a test, for example &lt;a href=&quot;https://nmap.org/&quot;&gt;Nmap&lt;/a&gt; or &lt;a href=&quot;https://github.com/rapid7/metasploit-framework&quot;&gt;Metasploit&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It turns out this is relatively straightforward using Docker Compose.  You can set-up a yml file with information on the containers you want to instantiate (the default name is docker-compose.yml) and then just spin that up with a single command.&lt;/p&gt;

&lt;p&gt;So for this setup the Docker Compose file looks like this&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-yaml&quot; data-lang=&quot;yaml&quot;&gt;&lt;span class=&quot;s&quot;&gt;sectest&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;raesene/sectest&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;command&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/bin/bash&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;links&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
     &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;dradis&lt;/span&gt;
     &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;openvas&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;dradis&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; 
  &lt;span class=&quot;s&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;raesene/auto-docker-dradis&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;ports&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; 
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;3000:3000&quot;&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;command&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;bundle exec rails server&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;openvas&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mikesplain/openvas&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;ports&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;443:443&quot;&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;9390:9390&quot;&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;9391:9391&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This file defines three containers that we’re going to use.  The first one is an instance of a basic Security Testing container that I created &lt;a href=&quot;https://github.com/raesene/sectest&quot;&gt;here&lt;/a&gt;.  There’s nothing too major in there it just sets up some tools that I commonly use on reviews.  In that first stanza we specify that the dradis and openvas containers are linked to that one, which is relevant when we start things up.&lt;/p&gt;

&lt;p&gt;In the next section we start up the dradis container and here it’s worth noting two points.  The first is the “ports” command.  This sets up port mappings so that the service will be visible on the docker host, which is where we’ll be connecting to it from.  The second thing to note is the “command” directive which just specifies what should be run when the container comes up.&lt;/p&gt;

&lt;p&gt;In the third section we specify the openvas container and set-up some port mappings to expose the relevant ports to the host.&lt;/p&gt;

&lt;p&gt;Now we’ve got this file created we just need to start things up.  The command I’ve used for this is&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker-compose run --service-ports sectest /bin/bash
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;What this does is start-up the sectest container and any linked containers (which is why it was important to add those links in the docker-compose.yml file), also the –service-ports option is specified so that the ports will be exposed, and lastly we specify the commmand to run, in this case /bin/bash.&lt;/p&gt;

&lt;p&gt;If all goes well this should download and start-up all three containers and you should have a command prompt in the sectest container, along with started accessible services for the other two containers.&lt;/p&gt;

</description>
				<pubDate>Sat, 15 Aug 2015 20:06:39 +0100</pubDate>
				<link>/blog/2015/08/15/set-up-a-complete-security-test-environment-with-command-and-docker-compose/</link>
				<guid isPermaLink="true">/blog/2015/08/15/set-up-a-complete-security-test-environment-with-command-and-docker-compose/</guid>
			</item>
		
			<item>
				<title>Using Docker for Security Testing</title>
				<description>&lt;p&gt;Following on from my &lt;a href=&quot;http://raesene.github.io/blog/2015/07/05/some-notes-on-docker/&quot;&gt;previous post&lt;/a&gt; about Docker, I’ve been giving some thoughts to how I could make use of this in my day-to-day work of security testing.&lt;/p&gt;

&lt;p&gt;There’s a couple of areas where I can see Docker being quite useful, mainly due to the ease of maintaining and installing applications and also the reduced resource utilization over “tradtional” virtual machines.&lt;/p&gt;

&lt;p&gt;The first one is in isolating security testing applications which require a bit of setup or a particular environment to operate in.  Some very useful security testing tools are slightly more complex to setup and run than just doing a  &lt;code class=&quot;highlighter-rouge&quot;&gt;git clone&lt;/code&gt; of the repo and running a script and there can always be conflicts in the version of underlying tools and libraries required for them to run. These tools can benefit from the isolation that using a containerized version brings.&lt;/p&gt;

&lt;p&gt;Already on &lt;a href=&quot;https://hub.docker.com&quot;&gt;Docker Hub&lt;/a&gt; you can see a number of containers avaiable which do this for you.  An example is &lt;a href=&quot;http://www.openvas.org/&quot;&gt;OpenVAS&lt;/a&gt; for which there are a number of containers available, for example &lt;a href=&quot;https://registry.hub.docker.com/u/mikesplain/openvas/&quot;&gt;this one&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;One of the nice things about containers built using the automated build approach is that Docker Hub will show you the dockerfile used to build the container, which provides some level of transparancy over what you’re downloading (and the syntax is relatively basic, so easy to see what’s going on).  You still obviously have to trust Docker Hub and the sources of data used to build the container, which may not be applicable to some environments, and there a better option might be an internal docker repository with internally validated builds.  Even there, the Docker Hub examples are useful to base your Dockerfiles on.&lt;/p&gt;

&lt;p&gt;Another way in which containers can be handy is in creating new, consistent, security test environments for each piece of work done.  A common problem in security testing is ensuring that your testing environment is clear of any data from previous reviews, to avoid inadvertant contamination and also ensuring that your tools are regularly updated.&lt;/p&gt;

&lt;p&gt;Using a containerized image as your base here is quite straightforward as you just get an image, and then create a new container based on that image for each review.  I’ve started a sample one &lt;a href=&quot;https://registry.hub.docker.com/u/raesene/sectest/&quot;&gt;here&lt;/a&gt; which shows some of the basic tools.  The Dockerfile is on github &lt;a href=&quot;https://github.com/raesene/sectest&quot;&gt;here&lt;/a&gt;, and could be useful as a starting point for others.&lt;/p&gt;

&lt;p&gt;Now you could replicate this with virtual machines, but the downside there is that the disk space requirements for a new VM per test would be pretty hefty and cloning/starting a new VM can be a bit slow, when compared to containers.  Depending on the type of testing you do, you may need the more complete environemnt that a VM provides, but I reckon for a lot of  testing a container should work just fine.&lt;/p&gt;

&lt;p&gt;Another potential advantage of this approach is that you could archive off the container at the end of the test which could make reproducing findings at a later date simpler (less risk of tools updates changing the results of a test)&lt;/p&gt;

&lt;h2 id=&quot;some-other-security-testing-containers&quot;&gt;Some Other Security Testing Containers&lt;/h2&gt;

&lt;p&gt;As I mentioned before there are quite a few containers turning up on Docker Hub which could be useful, here’s some of the ones I’ve seen so far&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://registry.hub.docker.com/u/raesene/auto-docker-dradis/&quot;&gt;Dradis community&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://registry.hub.docker.com/u/owasp/zap2docker-stable/&quot;&gt;OWASP ZAP&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://registry.hub.docker.com/u/kalilinux/kali-linux-docker/&quot;&gt;Kali Linux&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://registry.hub.docker.com/u/wpscanteam/wpscan/&quot;&gt;WPScan&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
				<pubDate>Thu, 23 Jul 2015 20:56:47 +0100</pubDate>
				<link>/blog/2015/07/23/using-docker-for-security-testing/</link>
				<guid isPermaLink="true">/blog/2015/07/23/using-docker-for-security-testing/</guid>
			</item>
		
	</channel>
</rss>
